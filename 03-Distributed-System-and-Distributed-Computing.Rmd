# 分布式系统与分布式计算

## 为什么选择分布式系统
2000年以前，计算机的计算性能相对薄弱，超级计算的核心技术被IBM等大型公司垄断，仅有大学、政
府机构、国防、军工等企业才有资格和能力购买使用超级计算机，普通用户只能使用计算能力相对较差
的个人计算机。2000年之后，计算机的硬件技术有了飞速的提升。摩尔定律指出IC上可容纳的晶体管数
目约每隔18个月便会增加一倍，性能也将提升一倍，也就是说随着时间的增加，计算机的性能会成倍提
升。但由于互联网经济的快速发展，数据的增长速度远远超过计算机硬件的革新速度，因此，即使有摩
尔定律的存在，个人计算机也不足以处理这些快速增长的数据。这时，我们急需一个新的模式，使得能
够以相对廉价的形式分析海量的数据。
另一方面，由于超级计算机自身的配置环境需求和开发成本的限制，IBM等大型互联网公司无法向个人
用户提供廉价、低功耗、计算性能更高的计算机。而分布式系统能够将许多廉价的个人计算机组装起来
，使得个人计算机能够达到相对高的计算性能，由此产生对分布式系统的需求。


## 分布式系统的性能体现
对于巨大体量的数据，单一计算机处理能力有限，处理耗费的时间长。一台具有四个I/O通道（每个通
道具有100MB/秒的吞吐量）的高端计算机将需要三个小时才能读取4TB的数据集。
而分布式系统能将巨大的数据集拆分为小块（blocks），通过分布式文件系统将数据块分布在系统内不
同的计算机上，各个计算机分别进行计算后将结果返回进行简单汇总处理即可。与超级计算机相比，通
过这种处理方式，分布式系统处理相同体量的数据所耗费的时间将大大缩短。


## 代码向数据移动逻辑
传统的超级计算机需要在客户端和服务器之间重复传输数据。对于需要大量计算的工作而言，这种方式
效果很好，但是对于数据密集型处理而言，往往因数据量太大而无法轻松移动。而分布式系统的客户端
仅发送要执行的程序，这些程序通常很小。更重要的是，在分布式系统中，数据被分解并分布在整个集
群的分布节点中，对数据的计算在该数据所在的计算机上进行，数据不需要在各个计算机之间传输，
I/O即输入输出的性能不再是影响计算的瓶颈，此时可以通过大规模的部署计算机来提升计算效率。
分布式系统中将代码传递到分布节点的过程通过MapReduce逻辑实现。MapReduce是一个分布式的计算框
架，分为Map和Reduce两个部分。Map过程将中心节点内涉及的算法传递给每一台分布节点计算机，
Reduce过程将每一台分布节点计算机的计算结果返回至中心节点，关于MapReduce的具体过程及优势劣
势将在后续进行介绍。

## 分布式系统的构成
分布式系统由分布式文件系统(Storage)、资源管理器(Resource Management)、应用程序、调度管理工具
(Zookeeper)构成，分布式文件系统具有执行文件存取的能力，并以透明方式对分布在分布式系统中的文
件进行管理和存取，相当于普通计算机的硬盘，数据在进行分布式存储之后才能进行分布式计算。常用的
分布式文件系为hadoop的HDFS。分布式系统的资源管理器负责集群资源管理调度和控制分布式程序，相当
于普通计算机的任务管理器，运行hadoop的资源管理器为YARN。分布式系统的应用程序类似于普通计算机
内的R/Python等应用程序，不同应用程序的应用取决于应用层级，当数据的操作涉及到机器学习可利用
SPARK的机器学习数据库；当涉及到分布式数据库学习可应用HBASE；当涉及到传统分布式系统的计算可应
用MapReduce等。分布式系统的调度管理工具用于监视分布式系统的健康状况，类似于普通计算机的系统
检查工具，杀毒软件。
分布式计算不是编程语言，而是一个框架，在这个框架下可以使用任何框架支持的编程语言，如
MapReduce支持几乎所有语言，SPARK支持R，Python等语言，HBASE支持SQL语言等。分布式系统能够提
供不同应用程序编程接口(API），编程语言通过API传递给分布式系统，再由资源管理器传递给分布式
系统各分布节点上的数据文件，各数据文件在其所在的计算机节点上进行计算。

## 与超级计算机的区别
分布式系统也叫做strongworker系统，与传统超级计算机不同的是，分布式系统的每一个计算节点也是
存储节点。
超级计算机的CPU是集成的，需要使用额外的工具进行集中计算，因此在整个过程中，计算与存储是拆
分开的。而分布式系统的计算和存储和在一起，分布式系统中的每一台计算机都可以储存一定体量的数
据，而且可以对相应体量的数据进行计算。