# Hadoop Streaming

## Hadoop上运行MapReduce

### 通过Hadoop Streaming运行MapReduce

Hadoop
Streaming是一个基础的API，它可以通过任何一种语言按照MapReduce的方式
去执行脚本文件，例如Mapper和Reducer脚本文件。它的原理类似于UNIX操作系统中的pipe管道操
作，使用Unix标准流作为Hadoop和用户程序之间的接口。Mapper和Reducer以键值对通过标准输入流（stdin）和标准输出流（stdout）进行输入和输
出，Reducer最后会将运行结果保存到HDFS中。Hadoop
Streaming最大的一个优势是在于它允许以
非Java语言编写MapReduce任务，这些任务能够与Java语言编写的任务一样在Hadoop集群中运
行。除此之外，Hadoop Streaming适合进行文本处理，比如从大型CSV文件中读取每一行的处理，Hadoop Streaming还可以处理二进制流，比如可以读取图像形式的输入。Hadoop Streaming支持Perl、Python、R等多种语言。

通过Hadoop
Streaming，任何可执行文件都可以被指定为Mapper/Reducer。这些可执行文件不需要事先
存放在集群上；如果不在worknodes里面，则需要用`-file`选项让framework把可执行文件作为
作业的一部分，一起打包提交。但是要处理的文件必须要放到Hadoop的HDFS上。

如果一个可执行文件被用于mapper，则在mapper初始化时， 每一个mapper任务会把这个可执行文件作为一个单独的进程启动。 mapper任务运行时，它把输入切分成行并把每一行提供给可执行文件进程的标准输入。 同时，mapper收集可执行文件进程标准输出的内容，并把收到的每一行内容转化成key/value对，作为mapper的输出。 如果一个可执行文件被用于reducer，每个reducer任务会把这个可执行文件作为一个单独的进程启动。 Reducer任务运行时，它把输入切分成行并把每一行提供给可执行文件进程的标准输入。 同时，reducer收集可执行文件进程标准输出的内容，并把每一行内容转化成key/value对，作为reducer的输出。
这是Map/Reduce框架和streaming mapper/reducer之间的基本通信协议。

由于Hadoop是用Java开发的，在使用hadoop
streming带来便利的同时，也存在一定的局限性，具体如下 1.
只能通过stdin和stdout来进行输入输出，不像 Java
的程序那样可以在代码里使用 API，控制力比较弱。 2.
Streaming默认只能处理文本数据Textfile，对于二进制数据，比较好的方法是将二进制的key,
value进行重编码，转化为文本。 3. 由于涉及转换过程，会带来更多的开销

以下为一个简单的Python版本的MapReduce执行过程，在本书中，我们将多次使用Python和R作为运行
MapReduce的程序。

-   上传数据到HDFS

        $ hadoop fs -put /home/dmc/TREASURE1.txt /

-   执行MapReduce

        $ hadoop jar /home/dmc/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.5.2.jar \
        -file /home/dmc/mapper.py /home/dmc/reducer.py \
        -input /TREASURE1.txt \
        -output WordsCount \
        -mapper "/home/dmc/mapper.py" \
        -reducer "/home/dmc/reducer.py" \

### Hadoop Streaming的常用参数设置


        -mapred.job.name: 设置作业名
        -input：指定作业输入，可以是文件或者目录，可以使用*通配符，也可以使用多次指定多个文件或者目录作为输入
        -output：指定作业输出目录，并且必须不存在，并且必须有创建该目录的权限，-output只能使用一次
        -mapper：指定mapper可执行程序或Java类，必须指定且唯一
        -reducer：指定reducer可执行程序或Java类
        -file：将指定的本地/hdfs文件分发到各个Task的工作目录下
        -jobconf mapred.reduce.tasks： 指定reducer的个数，如果设置为0或者-reducer NONE 则没有reducer程序，mapper的输出直接作为整个作业的输出
        -jobconf mapred.map.tasks 设置map任务个

### Hadoop其他MapReduce API

Hadoop是用Java编写的，有丰富的Java MapReduce模块类可供使用。
编译jar文件需要使用javac（在JDK中）和hadoop-mapreduce-client-core-xxx.jar，具体调用命令如下。

      javac -classpath $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar -d FirstJar\

      jar -cvf FirstJar.jar -C FirstJar/

Java版本的Hadoop语法为

      hadoop jar FirstJar.jar [mainClass] input output

虽然Hadoop是用Java语言写成的，但是MapReduce过程并不必须是用Java来写。除了以上介绍的Hadoop
Streaming以外，还有支持C++语言的Hadoop
Pipe的接口。
Hadoop Pipes是Hadoop MapReduce的C++接口的名称，Pipes框架通过Sockets实现用户编写的C++ Mapper/Reducer程序和Hadoop框架内的TaskTracker的数据通信。
Hadoop Pipe语法为

       hadoop pipes \
         -D hadoop.pipes.java.recordreader=true \
         -D hadoop.pipes.java.recordwriter=true \
         -input sample.txt \
         -output output \
         -program myCPProgram

这里再不做过多介绍， 感兴趣的读者可以参考
Hadoop官方文档或者[@white2012hadoop]、@sammer2012hadoop。

### 案例：单词计数

尝试使用MapReduce对文本文件数据中的单词进行计数(仅考虑原文本文件中不含标点符号，单词间使用空格分隔的情况)。
hadoop streaming允许用户提交不同脚本语言实现的MapReduce函数，这使得MapReduce过程可以使用不同脚本语言呈现，方便用户的使用操作。
本案例中`map`函数实现的功能为将文本文件中句子切分为单词，并将切分出的单词分别于1配对，以`word 1`的形式进行标准输出。下例中分别展示用python、R、bash语言实现的map函数。
使用python语言实现的map函数`map.py`：

       #! /usr/bin/env python3
       import sys
       wordcount={}
       for line in sys.stdin:
           line=line.strip()
           words=line.split(' ')
       for word in words:
           print('%s\t%s'% (word,1))

使用R语言实现的map函数`map.R`：

       #! /usr/bin/env Rscript
       input <- file('stdin','r')
       while(length(currentline <- readLines(input, n = 1, warn = FALSE)) > 0)
       {
           words = unlist(strsplit(currentline,' '))
           for(i in 1:length(words)){
               cat(words[i], 1, '\n', sep = ' ')
           }
       }

用bash语言实现的map函数`map.sh`：

        #! /usr/bin/env bash
        while read LINE; do
          for word in $LINE
          do
            echo "$word 1"
          done
        done

本案例中`reduce`函数实现的功能为接受`map`函数输出的`word 1`的数值对，并根据不同单词进行计数，计算出每个单词出现的次数。可使用如下python代码`reduce.py`实现该过程：

       #! /usr/bin/env python3
       import sys
       form operator import itemgetter
       wordcount = {}
       
       for line in sys.stdin:
           line = line.strip()
           word,count = line.split(' ')
           count = int(count)
           wordcount[word] = wordcount.get(word,0) + count
           
       sorted_wordcount = sorted(wordcount.items(),key = itemgetter(0))
       
       for word,count in sorted_wordcount:
           print('%s\t%s'%(word,count))
       
编写运行函数`main.sh`，在hadoop上实现上述MapReduce过程的运行。相应的bash代码如下所示，示例中使用python编写的map和reduce函数：

       #!/bin/bash

       PWD=$(cd $(dirname $0); pwd)
       cd $PWD 1> /dev/null 2>&1

       TASKNAME=word_count_1 

       HADOOP_INPUT_DIR=/user/devel/example/word_count.txt  #the input text to be dealed
       HADOOP_OUTPUT_DIR=/user/devel/example/output         #the directory of the output

       echo $HADOOP_INPUT_DIR
       echo $HADOOP_OUTPUT_DIR

       hadoop fs -rm -r $HADOOP_OUTPUT_DIR

       hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \
           -D mapred.job.name=TASKNAME \
           -D mapred.job.priority=NORMAL \
           -D stream.memory.limit=1000 \
           -D mapred.map.tasks=10 \
           -D mapred.reduce.tasks=7 \
           -D mapred.job.map.capacity=100 \
           -D mapred.job.map.capacity=100 \
           -input ${HADOOP_INPUT_DIR} \
           -output ${HADOOP_OUTPUT_DIR} \
           -mapper "python3 map.py" \
           -reducer "python3 reduce.py" \
           -file "$PWD/map.py" "$PWD/reduce.py"

       if [ $? -ne 0 ]; then
           echo 'error'
           exit 1
       fi
       
       hadoop fs -touchz ${HADOOP_OUTPUT_DIR}/done

       exit 0

如果用户有多个运行结构相同的map函数或reduce函数需要一一测试，如上述提到的`map.py`、`map.R`与`map.sh`，可以在编写`main.sh`时进行改动，使得其能够接受不同的函数进行相同的操作。相应代码如下：

       #!/bin/bash
       
       #add the time record for the MapReduce process
       echo '>>>>>>>>>>>>>>>> start:' `date`
       BEGIN_TIME=`date +%s`

       set -u

       #receive the needed files
       num=$#
       if [ $num -ne 4 ]; then
           echo -e "This program is designed for 1 mapper + 1 reducer + 1 inputfile."
           echo -e "please input the mapper file,reducer file ,input file and output path: sh main.sh mapper reducer inputfile outputpath\n"
           exit 1
       else
           MAPPER=${1}
           REDUCER=${2}
           INPUTFILE=${3}
           OUTPUTPATH=${4}
       fi


       PWD=$(cd $(dirname $0); pwd)
       cd $PWD 1> /dev/null 2>&1

       TASKNAME=word_count_2

       HADOOP_PREFIX=/user/devel/example
       HADOOP_INPUT_DIR=${HADOOP_PREFIX}/${INPUTFILE}
       HADOOP_OUTPUT_DIR=${HADOOP_PREFIX}/${OUTPUTPATH}

       echo $HADOOP_INPUT_DIR
       echo $HADOOP_OUTPUT_DIR

       hadoop fs -rmr $HADOOP_OUTPUT_DIR 

       hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \
           -jobconf mapred.reduce.tasks=1 \
           -input ${HADOOP_INPUT_DIR} \
           -output ${HADOOP_OUTPUT_DIR} \
           -file ${MAPPER} ${REDUCER} \
           -mapper ${MAPPER} \
           -reducer ${REDUCER}

       if [ $? -ne 0 ]; then
           echo 'error'
           exit 1
       fi
       
       hadoop fs -touchz ${HADOOP_OUTPUT_DIR}/done

       #record the end time and print the cost time
       END_TIME=`date +%s`

       echo '******Total cost '  $(($END_TIME-$BEGIN_TIME)) ' seconds'
       echo '>>>>>>>>>>>>>>>> end:' `date`
       echo "=============SUCCESSFUL============="

       exit 0

使用上述运行文件时，应传入四个参数，分别为map函数、reduce函数、输入的待处理文件与结果输出路径，可直接使用如下代码调用`map.R`与`reduce.py`，处理`/user/devel/example/word_count.txt`文件，并将输出结果保存至`/user/devel/example/output`文件夹内。

       sh main.sh map.R reduce.py word_count.txt output




